{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datasketch import MinHash\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones\n",
    "Hay 1 nueva, jaccard_difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_retweet(tweet:str):\n",
    "    if tweet.startswith('RT'):\n",
    "        tweet = ''.join(tweet.split(': ')[1:])\n",
    "    return tweet\n",
    "\n",
    "def limpiar_hashtag(tweet:str):\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def limpiar_url(tweet:str):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def limpiar_emoji(tweet:str):\n",
    "    tweet = re.sub(r'\\\\x\\w+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def limpiar_puntuacion(tweet:str):\n",
    "    tweet = re.sub(r'[^\\w\\s@]', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def limpiar_espacios(tweet:str):\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def limpiar_mayusculas(tweet:str):\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "\n",
    "def remplazar_tildes(tweet:str):\n",
    "    tweet = tweet.replace('á', 'a')\n",
    "    tweet = tweet.replace('é', 'e')\n",
    "    tweet = tweet.replace('í', 'i')\n",
    "    tweet = tweet.replace('ó', 'o')\n",
    "    tweet = tweet.replace('ú', 'u')\n",
    "    return tweet\n",
    "\n",
    "def limpiar_texto(tweet:str):\n",
    "    tweet = limpiar_retweet(tweet)\n",
    "    tweet = limpiar_hashtag(tweet)\n",
    "    tweet = limpiar_url(tweet)\n",
    "    tweet = limpiar_emoji(tweet)\n",
    "    tweet = limpiar_puntuacion(tweet)\n",
    "    tweet = limpiar_espacios(tweet)\n",
    "    tweet = limpiar_mayusculas(tweet)\n",
    "    tweet = remplazar_tildes(tweet)\n",
    "    tweets = tweet.strip()\n",
    "    return tweet\n",
    "\n",
    "def shingles(k, words: np.ndarray):\n",
    "    shingles = []\n",
    "    for i in range(0, len(words)):\n",
    "        shingles.append(' '.join(words[i:i+k]))\n",
    "    return list(set(shingles))\n",
    "\n",
    "def jaccard_difference(set1, set2):\n",
    "    intersection = np.intersect1d(set1, set2)\n",
    "    union = np.union1d(set1, set2)\n",
    "    if len(union) == 0:\n",
    "        return 0.0  # or any other default value\n",
    "    return 1.0 - len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrimos y limpiamos datos\n",
    "Ojo que para que pueda hacer pruebas, solamente considero los primeros 1000 datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\n",
    "    '/home/bcm/Desktop/PUC/Procesamiento de datos masivos/T1_Grupo/iic2440-tarea_1/Datos/tweets_2022_abril_junio.csv',\n",
    "    usecols=['id', 'screen_name', 'text'],\n",
    "    index_col='id',\n",
    "    dtype={'screen_name': str, 'text': str},\n",
    "    nrows=1000\n",
    "    )\n",
    "tweets = tweets.drop_duplicates(subset='text', keep=False)\n",
    "tweets = tweets.dropna()\n",
    "tweets['text'] = tweets.loc[:, 'text'].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-3\n",
    "Creamos Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2 # Shingles size\n",
    "tweets['shingles'] = tweets['text'].str.split().apply(lambda x: np.array(x)).apply(lambda x: shingles(k, x))\n",
    "shings = tweets['shingles'].to_numpy()\n",
    "u_shingles = np.unique(np.concatenate(shings)) # Shingles unicos en una unica lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Creamos matriz caracteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguimos coordenadas de filas y columnas en donde shingle esta en tweet.\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for i, tweet in enumerate(tweets['text']):\n",
    "    for j, shingle in enumerate(u_shingles):\n",
    "        if shingle in tweet:\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(1)\n",
    "\n",
    "sparse_matrix = coo_matrix((data, (rows, cols)), shape=(len(tweets['text']), len(u_shingles))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "Creamos minhashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minhashes = []\n",
    "num_hashes = 10\n",
    "num_perm = sparse_matrix.shape[0]\n",
    "\n",
    "\n",
    "for i in range(num_hashes):\n",
    "    seed = random.randint(0, 2**32 - 1)\n",
    "    minhash = MinHash(num_perm=num_perm, seed=seed)\n",
    "\n",
    "    for shingle in u_shingles:\n",
    "        minhash.update(shingle.encode('utf-8'))\n",
    "    mapped_values = [int(value) % sparse_matrix.shape[0] for value in minhash.hashvalues]\n",
    "    minhash.hashvalues = mapped_values\n",
    "    minhashes.append(minhash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos matriz permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos permute, que es la matriz con los minhashes y los valores randoms permutados\n",
    "\n",
    "permute = np.zeros((len(minhashes), len(minhashes[0].hashvalues)))\n",
    "\n",
    "for i, minhash in enumerate(minhashes):\n",
    "    # Get the hash values from the MinHash object\n",
    "    hash_values = minhash.hashvalues\n",
    "\n",
    "    # Assign the hash values to the corresponding row in the signature matrix\n",
    "    permute[i] = hash_values\n",
    "\n",
    "permute = permute.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "Creamos matriz signature, con caracteristica (sparse_matrix) y permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocupando permute y la caracteristica (Sparse matrix), calculamos la signature\n",
    "\n",
    "num_documents = sparse_matrix.shape[1]\n",
    "num_signatures = len(minhashes)\n",
    "signature_matrix = np.zeros((num_signatures, num_documents))\n",
    "\n",
    "sparse_matrix = sparse_matrix.tocsc()\n",
    "\n",
    "for i in range(num_documents):\n",
    "    non_zero_rows = np.nonzero(sparse_matrix[:, i])[0]\n",
    "\n",
    "    if non_zero_rows.size > 0:\n",
    "        for s in range(num_signatures):\n",
    "            signature_matrix[s, i] = np.min(permute[non_zero_rows, s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos diferencia jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = distance.squareform(distance.pdist(signature_matrix.T, metric=jaccard_difference))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
